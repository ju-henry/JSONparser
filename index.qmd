---
title: "JSON parser speed comparison"
format: 
  html:
    css: style.css
bibliography: references.bib
---

```{r results='hide', echo=FALSE}
library(ggplot2)
```
<br>

## Question

::: {.justify}

Parsing a few json files in R is often done using e.g. **jsonlite**. But if the 
files grow in number (to hundreds of thousands or millions) or size, are there 
faster tools to parse them?  

:::

<br>

## Tools

::: {.justify}

Here I compare three tools:  

- [**jsonlite**](https://cran.r-project.org/web/packages/jsonlite/index.html) [@jsonlite]
- [**jq**](https://jqlang.org/) [@jq]
- [**simdjson**](https://simdjson.org/) [@simdjson]

**jsonlite** is an R package while **jq** and **simdjson** have bindings for R:  

- [**jqr**](https://cran.r-project.org/web/packages/jqr/index.html) [@jqr]
- [**RcppSimdJson**](https://cran.r-project.org/web/packages/RcppSimdJson/index.html) [@rcppsimdjson]

To add some elements to the comparison, I also use **jq** as a stand-alone 
program (from the shell) as well as a Python binding for **simdjson**:  

- [**pysimdjson**](https://pysimdjson.tkte.ch/index.html) [@pysimdjson]

The GNU utility **time** [@gnutime] is used to measure elapsed wall-clock time.

:::

<br>

## Experiments 

::: {.justify}

I run experiments using public X (Twitter) data in three scenarios:  

- **base**: 100 lightweight (~4kB) jsons (one json represents infos about a single tweet).
- **heavy**: 100 heavier (~1MB) jsons (where entries have been duplicated in files of the base case to reach ~1MB each).
- **many**: ~25'000 lightweight files (~100MB overall) using many copies of each file in the base case. 

For all jsons, I am interested in extracting the same 21 fields (e.g. *created_at*, *user.name*,...) 
and write a final csv file to disk. This matters since both **jq** and **simdjson** 
offer the possibility to query specific entries directly in the parse command.
The fields I am interested in are sometimes nested and 6 of them require the application of a 
function to get the number of characters or to get the number of entries (nchar() or length(), in R). 

In the **heavy** case, entries to be retrieved are randomly located in each file, 
among all duplicated entries - that are marked with an integer suffix. 

In order to get stable results, all experiments are run 5 times and the median value is used.

:::

<br>

## Results

### Graph

```{r echo=F}
df <- read.csv("results_logs_median.csv")
```

```{r echo=F}
ggplot(df, aes(x = case, y = time, colour = tool)) + 
  geom_point(size = 3) + 
  theme_minimal() +
  scale_y_continuous(breaks = seq(0, ceiling(max(df$time)), by = 1)) + 
  theme(panel.grid.major.y = element_line(color = "grey"))
```

### Table

```{r echo=FALSE}
df <- df[order(df$case, df$tool),]
B <- matrix(data = df$time, nrow = length(unique(df$tool)), ncol = length(unique(df$case)), byrow = F)
dfB <- data.frame(B, row.names = df$tool[1:nrow(B)])
names(dfB) <- unique(df$case)
print(dfB)
```

### Observations

::: {.justify}

-  **Pysimdjson** dominates other tools in the last two cases and comes second to **jq** in the base case. Contrarily to other tools / bindings, it is barely affected by the size of the files (second case). **Pysimdjson** also does much better than its R counterpart (**rcppsimdjson**).
- As one could expect, **jq** fares better than its R binding (**jqr**).
- R-based tools seem to suffer in the last case (maybe because of the long *for* loop).

:::

<br>

## Conclusion

**pysimdjson** seems to be the obvious answer, being faster than other tools when json files are heavy or many.

<br>

## Reproductibility

Measured values cannot be reproduced (since they depend on hardware, software, OS,...), but I would expect that **pysimdjson** remains the fastest tool if SIMD is possible on your machine. If you would like to run the experiments, you can clone the repository and use the Dockerfile:

```{bash}
#| eval: false
#| echo: true

git clone https://github.com/ju-henry/JSONparser.git
cd JSONparser
docker build -t parse_exp .
docker run --cpus=1 --memory=2g --rm -v "$(pwd):/output" parse_exp
# results can be found in: results_logs_median.csv

# to generate the report with the graph, you can do:
quarto render index.qmd
```

<br>
